name: infra/cluster-init

on:
  # Automatically run CI on Release and Pre-Release tags and main branch
  # (only if there are changes to relevant paths)
  push:
    tags:
      - "cluster-init/v[0-9]+.[0-9]+.[0-9]+*"
    branches:
      - main
    paths:
      - ".github/workflows/cluster-init.yaml"
      - "infra/cluster-init/**"

  # Automatically run CI on branches, that have active PR opened
  pull_request:
    branches:
      - main
    paths:
      - ".github/workflows/cluster-init.yaml"
      - "infra/cluster-init/**"

  # To make it possible to trigger e2e CI workflow for any arbitrary git ref
  workflow_dispatch:

jobs:
  release-rules:
    runs-on: ubuntu-latest
    outputs:
      release-type: ${{ steps.release-rules.outputs.release-type }}
    steps:
      - uses: actions/checkout@v2
      - id: release-rules
        uses: ./.github/actions/release-rules
        with:
          prefix: cluster-init/

  publish:
    # Automatically publish release and pre-release artifacts.
    #
    # As for dev releases, make it possible to publish artifacts
    # manually by approving 'deployment' in the 'manual' environment.
    #
    # Dev build can be released either from the 'main' branch or
    # by running this workflow manually with `workflow_dispatch` event.
    if: >-
      contains('release,pre-release', needs.release-rules.outputs.release-type)
        || ( github.event_name != 'pull_request' )
        || ( github.event.pull_request.head.repo.full_name == github.repository )
    environment: ${{ needs.release-rules.outputs.release-type == 'dev' && 'manual' || '' }}
    runs-on: ubuntu-latest
    needs:
      - release-rules
      - test-e2e
    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0

      - name: Log in to the Container registry
        uses: docker/login-action@v1
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build Docker Image
        id: build
        working-directory: infra/cluster-init
        env:
          DOCKER_REGISTRY: ghcr.io/${{ github.repository }}
        run: |
          set -o pipefail
          make build-image | tee output.log
          echo "::set-output name=cluster-init-image::$(sed -n 's%Building docker image: \(.*\)%\1%p' output.log)"

      - name: Publish Cluster Init Docker Image
        run: docker push ${{ steps.build.outputs.cluster-init-image }}

  test-e2e:
    runs-on: ubuntu-latest
    env:
      CLUSTER_NAME: turing-e2e
      ISTIO_VERSION: 1.9.9
      KNATIVE_VERSION: v0.18.3
      KNATIVE_ISTIO_VERSION: v0.18.1
      LOCAL_REGISTRY: registry.localhost:5000

    steps:
      - name: Check out code
        uses: actions/checkout@v2
        with:
          fetch-depth: 0
      
      - name: "Setup local k8s cluster"
        uses: AbsaOSS/k3d-action@v1.5.0
        with:
          cluster-name: ${{ env.CLUSTER_NAME }}
          use-default-registry: true
          args: >-
            --servers 1
            --agents 3
            --port 80:80@loadbalancer
            --k3s-server-arg "--no-deploy=traefik,metrics-server"

      - name: Build Docker image
        id: build-image
        working-directory: infra/cluster-init
        run: |
          set -o pipefail
          make build-image | tee output.log
          echo "::set-output name=cluster-init-version::$(sed -n 's%turing-cluster-init version: \(.*\)%\1%p' output.log)"

      - name: Save Docker image
        run: |
          docker image save \
            --output cluster-init.${{ steps.build-image.outputs.cluster-init-version }}.tar \
            cluster-init:${{ steps.build-image.outputs.cluster-init-version }}

      - name: Publish images to local registry
        env:
          DOCKER_REPOSITORY: ${{ env.LOCAL_REGISTRY }}/${{ github.repository }}
          CLUSTER_INIT_VERSION: ${{ steps.build-image.outputs.cluster-init-version }}
        run: |
          # Cluster init
          docker image load --input cluster-init.${{ env.CLUSTER_INIT_VERSION }}.tar
          docker tag \
            cluster-init:${{ env.CLUSTER_INIT_VERSION }} \
            ${{ env.DOCKER_REPOSITORY }}/cluster-init:${{ env.CLUSTER_INIT_VERSION }}
          docker push ${{ env.DOCKER_REPOSITORY }}/cluster-init:${{ env.CLUSTER_INIT_VERSION }}

      - name: Install Infrastructure
        env:
          CLUSTER_INIT_VERSION: ${{ steps.build-image.outputs.cluster-init-version }}
        run: |
          kubectl create ns infrastructure
          helm upgrade turing-init infra/charts/turing-init \
            --namespace infrastructure \
            --set image.registry=${{ env.LOCAL_REGISTRY }}/ \
            --set image.repository=${{ github.repository }}/cluster-init \
            --set image.tag=${{ env.CLUSTER_INIT_VERSION }} \
            --set knative.domains="127.0.0.1.nip.io" \
            --set knative.registriesSkippingTagResolving=${{ env.LOCAL_REGISTRY }} \
            --install \
            --wait

          # wait for install infra job to finish
          kubectl logs -n infrastructure -f $(kubectl get pod --namespace infrastructure | grep -v 'NAME' | grep -v 'spark' | head -n 1 | awk '{print $1}')
          kubectl get pod --all-namespaces
          kubectl get svc --all-namespaces
          kubectl wait -n infrastructure --for=condition=complete --timeout=10m job/turing-init-spark-operator-webhook-init
          # Might fail the first time but the 2nd run should work, rarely fails on the first try though.
          kubectl wait -n infrastructure --for=condition=complete --timeout=10m job/turing-init-init

      - name: Smoke Test
        run: |
          tee service.yaml <<EOF 
          apiVersion: serving.knative.dev/v1
          kind: Service
          metadata:
            name: helloworld-go 
            namespace: default
          spec:
            template:
              spec:
                containers:
                  - image: gcr.io/knative-samples/helloworld-go
                    env:
                      - name: TARGET
                        value: "Hello Knative Serving is up and running!!"
          EOF


          kubectl apply -f service.yaml
          timeout --foreground 120 bash -c 'until kubectl get service.serving.knative.dev/helloworld-go --output=jsonpath='{.status.conditions[1]}'  | grep "True"; do : ; done'
          kubectl get ksvc
          kubectl apply -f https://github.com/knative/serving/releases/download/knative-v1.1.0/serving-default-domain.yaml
          curl -v http://helloworld-go.default.127.0.0.1.sslip.io
          kubectl delete service helloworld-go 
      
      - name: Tear down infrastructure job
        run: helm delete --namespace infrastructure turing-init --timeout 15m
